#' Run LPJmL
#'
#' LPJmL is run using `"config_*.json"` files written by
#' \link[lpjmlKit]{write_config}. \link[lpjmlKit]{write_config} returns a tibble
#' that can be used as an input (see `x`). It serves the details to run single
#' or multiple (dependent/subsequent) model runs.
#'
#' @param x \link[tibble]{tibble} with at least `"sim_name"` defined as columns.
#' Runs as rows. Optional run parameters `"order"` and
#' `"dependency"` used for subsequent runs (see details)
#' \link[lpjmlKit]{write_config} returns a tibble in the required format.
#' OR provide a character string (vector) with the file_name of a or
#' multiple generated ( \link[lpjmlKit]{write_config}) configuration file(s).
#'
#' @param model_path character string providing the path to LPJmL
#' (equal to LPJROOT)
#'
#' @param output_path character string - if `output_path` differs from
#' `model_path` - path where an output, a restart and a configuration
#' folder are created
#'
#' @param parallel_cores integer defining the number of available CPU
#' cores/nodes for parallelization. Defaults to `1` (no parallelization). Please
#' note that parallelization is only supported for slurm jobs and not for
#' interactive runs
#'
#' @param write_stdout logical. If TRUE `stdout` as well as `stderr` files are
#' written instead of printing it. Within a Slurm Job `write_stdout` is
#' automatically set to `TRUE`. Default is `FALSE`
#'
#' @return see `x`, extended with columns `"type"`, `"job_id"` and `"status"`
#'
#' @details
#' Supply a \link[tibble]{tibble} for `x` that has been generated by
#' \link[lpjmlKit]{write_config} and can look like the following examples:
#'
#' | **sim_name**    |
#' |:--------------- |
#' | scen1_spinup    |
#' | scen2_transient |
#'
#' To perform subsequent or rather nested runs provide optional run parameters
#' `"order"` and `"dependency"` to the initial \link[tibble]{tibble} supplied as
#' `param` to \link[lpjmlKit]{write_config}
#'
#' | **sim_name**    | **order** | **dependency** |
#' |:--------------- | ---------:|:-------------- |
#' | scen1_spinup    | 1         | NA             |
#' | scen2_transient | 2         | scen1 _spinup  |
#'
#'
#' As a shortcut it is also possible to provide the config file
#' `"config_*.json"` as a character string or multiple config files as a
#' character string vector directly as `x` to `run_lpjml`. \cr
#' Also be aware that the order of the supplied config files is important
#' (e.g. make sure the spin-up run is run before the transient one)
#'
#' @examples
#'
#' \dontrun{
#' library(lpjmlKit)
#' library(tibble)
#'
#' model_path <- "./LPJmL_internal"
#' output_path <-"./my_runs"
#'
#' # basic usage
#' my_params1 <- tibble(
#'   sim_name = c("scen1", "scen2"),
#'   startgrid = c(27410, 27410)
#'   river_routing = c(FALSE, FALSE),
#'   random_seed = c(42, 404),
#'   pftpar.1.name = c("first_tree", NA),
#'   param.k_temp = c(NA, 0.03),
#'   new_phenology = c(TRUE, FALSE)
#' )
#'
#' config_details1 <- write_config(my_params1, model_path, output_path)
#'
#'  run_details1 <- run_lpjml(
#'   x = config_details1,
#'   model_path = model_path,
#'   output_path = output_path
#' )
#'
#' run_details1
#' #   sim_name      job_id   status
#' #   <chr>           <int>  <chr>
#' # 1 scen1              NA  run
#' # 2 scen2              NA  run
#'
#'
#' # with run parameters dependency, order being set (also less other
#' #   parameters than in previous example)
#' my_params2 <- tibble(
#'   sim_name = c("scen1", "scen2"),
#'   startgrid = c(27410, 27410)
#'   river_routing = c(FALSE, FALSE),
#'   random_seed = c(42, 404),
#'   order = c(1, 2),
#'   dependency = c(NA, "scen1_spinup")
#' )
#'
#' config_details2 <- write_config(my_params2, model_path, output_path)
#'
#' run_details2 <- run_lpjml(config_details2, model_path, output_path)
#'
#' run_details2
#' #   sim_name        order dependency   type       job_id   status
#' #   <chr>           <dbl> <chr>        <chr>      <chr>    <chr>
#' # 1 scen1_spinup        1 NA           simulation NA       run
#' # 2 scen1_transient     2 scen1_spinup simulation NA       run
#'
#'
#' # same but by using the pipe operator
#' run_details2 <- tibble(
#'   sim_name = c("scen1_spinup", "scen1_transient"),
#'   random_seed = as.integer(c(1, 42)),
#'   order = c(1, 2),
#'   dependency = c(NA, "scen1_spinup")
#' ) %>%
#'   write_config(model_path, output_path) %>%
#'   run_lpjml(model_path, output_path)
#'
#'
#' # shortcut approaches
#' run_details3 <- run_lpjml(
#'   x = "./config_scen1_transient.json",
#'   model_path = model_path,
#'   output_path = output_path
#' )
#'
#' run_details4 <- run_lpjml(
#'   c("./config_scen1_spinup.json", "./config_scen1_transient.json"),
#'   model_path,
#'   output_path
#' )
#'
#' }
#'
#' @md
#' @export
run_lpjml <- function(x,
                      model_path,
                      output_path = NULL,
                      parallel_cores = 1,
                      write_stdout = FALSE) {

  # check if model_path is set or unit test flag provided
  if (!dir.exists(model_path)) {
    if (model_path != "TEST/PATH") {
      stop(
        paste0("Folder of model_path \"", model_path, "\" does not exist!")
      )
    }
  }
  if (is.null(output_path)) output_path <- model_path

  # case if character vector with file names is supplied instead of tibble
  if (is(x, "character")) {
    x <- tibble::tibble(sim_name = sapply(
      x,
      function(x) {
        strsplit(
          strsplit(rev(strsplit(x, "/")[[1]])[1], "config_")[[1]][2],
          ".json"
        )[[1]]
      }
    ))
  }
  x$type <- "simulation"
  x$job_id <- NA
  x$status <- "failed"

  if ("order" %in% colnames(x)) {
    for (order in unique(sort(x$order))) {
      sim_names <- x$sim_name[which(x$order == order)]
      if (parallel_cores == 1) {
        do_sequential(sim_names, model_path, output_path, write_stdout)
      } else if (parallel_cores > 1 && Sys.getenv("SLURM_JOB_ID") != "") {
        do_parallel(sim_names, model_path, output_path, parallel_cores)
      } else {
        stop(paste0("Parallelization is only supported for slurm jobs. Also",
                    " please set parallel_cores to a value between 1 (non",
                    " parallel) and n parallel cores/nodes."))
      }
    }
  } else {
    if (parallel_cores == 1) {
      do_sequential(x$sim_name, model_path, output_path, write_stdout)
    } else if (parallel_cores > 1 && Sys.getenv("SLURM_JOB_ID") != "") {
      do_parallel(x$sim_name, model_path, output_path, parallel_cores)
    } else {
      stop(paste0("Parallelization is only supported for slurm jobs. Also",
                  " please set parallel_cores to a value between 1 (non",
                  " parallel) and n parallel cores/nodes."))
    }
  }
  x$status[x$type == "simulation"] <- "run"
}


# inner run function
do_run <- function(sim_name,
                   model_path,
                   output_path,
                   write_stdout) {
  config_file <- paste0("config_",
                        sim_name,
                        ".json")
  timestamp <- format(Sys.time(), "%Y%m%d_%H%M")
  if (Sys.getenv("SLURM_JOB_ID") != "") {
    write_stdout <- TRUE
  }
  # when running inside a slurm job it ensures to propagate ressources
  inner_command <-  paste0(ifelse(Sys.getenv("SLURM_JOB_ID") == "",
                                  "",
                                  "srun --propagate "),
                           model_path,
                           "/bin/lpjml ",
                           output_path,
                           "/configurations/",
                           config_file)
  stdout_file <- ifelse(write_stdout,
                        paste0(output_path,
                               "/output/",
                               sim_name,
                               "/",
                               "outfile_",
                               timestamp,
                               ".out"),
                        "|")

  cat(paste0("\nRunning LPJmL for config: ", config_file, "...\n"))
  if (write_stdout) {
    cat(paste0("View output at \"", stdout_file, "\"\n"))
  }
  processx::run(command = "sh",
                args = c("-c", inner_command),
                stdout = stdout_file,
                stderr = ifelse(write_stdout,
                                paste0(output_path,
                                       "/output/",
                                       sim_name,
                                       "/",
                                       "errfile_",
                                       timestamp,
                                       ".err"),
                                "|"),
                echo = TRUE,
                cleanup_tree = TRUE,
                spinner = ifelse(write_stdout &&
                                 Sys.getenv("SLURM_JOB_ID") == "",
                                            TRUE,
                                            FALSE))
}


# conduct sequential runs (no parallelization), also switch of MPI on login node
do_sequential <- function(sim_names, model_path, output_path, write_stdout) {
  # tryCatch to unset and set MPI for function call outside of slurm job on
  #   the PIK cluster even when function call is interrupted or has thrown
  #   an error
  tryCatch({
    # workarounds by Ciaron
    if (dir.exists("/p/system") && Sys.getenv("SLURM_JOB_ID") == "") {
      Sys.setenv(I_MPI_DAPL_UD = "disable",
                 I_MPI_FABRICS = "shm:shm",
                 I_MPI_DAPL_FABRIC = "shm:sh")
    }
    for (sim_name in sim_names) {
      do_run(sim_name, model_path, output_path, write_stdout)
    }
  }, finally = {
    # workarounds by Ciaron
    if (dir.exists("/p/system") && Sys.getenv("SLURM_JOB_ID") == "") {
      Sys.setenv(I_MPI_DAPL_UD = "enable",
                 I_MPI_FABRICS = "shm:dapl")
      Sys.unsetenv("I_MPI_DAPL_FABRIC")
    }
  })
}


# conduct parallel runs
do_parallel <- function(sim_names, model_path, output_path, parallel_cores) {
  # create temporary file to store stdout and stderr within parallel mode
  error_file <- tempfile(fileext = ".txt")
  # create and register cluster based on available CPU cores/nodes
  cl <- parallel::makeCluster(parallel_cores, outfile = error_file)
  doParallel::registerDoParallel(cl)
  sim_name <- NULL
  # parallel foreach sim_name
  job_details <- foreach::foreach(sim_name = sim_names,
                                  .errorhandling = "stop"
  ) %dopar% {
    # write single call
    tryCatch({
      do_run(sim_name, model_path, output_path, write_stdout = TRUE)
    # stop when error occures
    }, error = function(e) {
      # check if error is returned
      if (e != "") {
        # error with hint to deactivate parallelization
        stop(paste0(e,
                    " - Please set parallel_cores=1 for traceback ",
                    "functionality (only available without",
                    " parallelization)",
                    call. = FALSE))
      } else {
        # hint to deactivate parallelization
        stop(paste0("This is not a common error,",
                    " please set parallel_cores=1 for traceback ",
                    "functionality (only available without",
                    " parallelization"))
      }
    })
  }
  # close cluster
  parallel::stopCluster(cl)
}
